% Chapter Template

\chapter{Conclusiones} % Main chapter title

\label{Chapter5} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}
Este capítulo presenta las conclusiones generales del trabajo y sintetiza los principales aportes derivados del desarrollo del motor de afinidad. A partir de la integración de múltiples fuentes de datos, técnicas avanzadas de preprocesamiento y la comparación sistemática de distintos enfoques de recomendación, se establecen aquí las lecciones centrales obtenidas, el valor añadido por la solución propuesta y su relevancia dentro del ecosistema comercial de BEES.
Asimismo, se discuten las oportunidades de mejora y las líneas de trabajo futuras que permitirían ampliar el alcance del sistema, fortalecer su desempeño y consolidar su impacto operativo.


%----------------------------------------------------------------------------------------

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

\section{Conclusiones generales }

El trabajo realizado permitió diseñar, construir y validar un motor de afinidad integral para personalización de portafolio en un entorno B2B de consumo masivo, caracterizado por alta heterogeneidad, fuerte concentración en productos y clientes, y un nivel de rotación y estacionalidad significativamente mayor que en los benchmarks clásicos de recomendación. A lo largo del proyecto se desarrolló una solución completa que abarca desde la consolidación y depuración de múltiples fuentes de datos hasta la implementación y comparación de modelos avanzados, que incorpora además prácticas modernas de ingeniería y MLOps necesarias para operar a gran escala.

Un primer aporte central del trabajo fue la integración de un conjunto diverso de fuentes informativas: transacciones históricas, señales digitales, atributos estructurales de clientes y productos y ventanas temporales de comportamiento. Estas fuentes fueron sometidas a un proceso riguroso de curación, normalización, discretización y estandarización que permitió construir insumos robustos, comparables y libres de sesgos extremos de escala. El diseño de la matriz cliente–producto, junto con el score compuesto derivado de seis meses de señales ponderadas, constituye un artefacto original del proyecto y un insumo que no existía previamente en la operación.

El segundo aporte clave se encuentra en la profundidad del preprocesamiento y en la construcción sistemática de atributos contextuales. El trabajo no se limitó a generar una matriz de interacciones, sino que modeló bloques completos de features de negocio para clientes y productos, evaluó su calidad informativa mediante análisis de varianza, correlación, similitud geométrica y PCA, y demostró que estas representaciones capturan patrones reales del comportamiento comercial. Este análisis permitió no solo mejorar el desempeño de los modelos híbridos, sino también aportar un entendimiento más profundo de la estructura comercial del ecosistema.

En términos de modelado, el proyecto avanzó de manera progresiva desde métodos clásicos hasta arquitecturas modernas. Se implementaron \textit{baselines}, un modelo ALS optimizado, modelos híbridos con \textit{LightFM}, una arquitectura \textit{Two-Tower} con embeddings aprendidos y un modelo neuronal de tipo NCF, que combina enfoques colaborativos, de contenido y de aprendizaje profundo. La comparación sistemática de estos modelos y su evaluación temporal permitió identificar claramente el aporte incremental de cada técnica y construir una solución que balancea precisión, diversidad y costo computacional en un contexto real de negocio.

A diferencia de los \textit{benchmarks} tradicionales, basados en datasets densos, abundancia de señales explícitas y comportamiento de consumo individual, este trabajo enfrentó un contexto B2B con interacción dispersa, señales implícitas ruidosas, productos con vida útil acotada y clientes con ciclos de compra irregulares. El motor de afinidad desarrollado se diferencia de los estándares B2C al incorporar criterios de negocio, representaciones híbridas, tratamiento explícito del arranque en frío y un pipeline de validación temporal, elementos imprescindibles para que las recomendaciones sean útiles en un entorno distribuido y operativo como el de consumo masivo.

Otro aporte distintivo del proyecto fue el desarrollo de una infraestructura completa de MLOps, que incluye el pipeline de preparación, entrenamientos reproducibles en Spark, optimización automática de hiperparámetros con \texttt{Optuna}, registración estructurada de artefactos en \texttt{MLFlow}, versionado de modelos y diseño conceptual de despliegue. Esta dimensión técnica asegura que el sistema no sea únicamente un prototipo académico, sino una solución realista, escalable y alineada con los requerimientos del entorno de producción.

Finalmente, el análisis de robustez temporal demostró que el sistema mantiene estabilidad y generalización frente a variaciones mensuales del comportamiento, diferencias estructurales entre unidades de negocio y heterogeneidad entre clasificaciones de clientes. Este comportamiento consistente valida la solidez del motor de afinidad y confirma que la integración de múltiples señales y atributos permite capturar patrones de demanda relevantes incluso en entornos altamente volátiles.

El trabajo aporta una solución integral que combina rigurosidad técnica, viabilidad operativa y comprensión profunda del negocio, y constituye un avance relevante tanto para la empresa como para la literatura aplicada de sistemas de recomendación en entornos B2B de consumo masivo.


% La idea de esta sección es resaltar cuáles son los principales aportes del trabajo realizado y cómo se podría continuar. Debe ser especialmente breve y concisa. Es buena idea usar un listado para enumerar los logros obtenidos.

% En esta sección no se deben incluir ni tablas ni gráficos.

% Algunas preguntas que pueden servir para completar este capítulo:

% \begin{itemize}
% \item ¿Cuál es el grado de cumplimiento de los requerimientos?
% \item ¿Cuán fielmente se puedo seguir la planificación original (cronograma incluido)?
% \item ¿Se manifestó algunos de los riesgos identificados en la planificación? ¿Fue efectivo el plan de mitigación? ¿Se debió aplicar alguna otra acción no contemplada previamente?
% \item Si se debieron hacer modificaciones a lo planificado ¿Cuáles fueron las causas y los efectos?
% \item ¿Qué técnicas resultaron útiles para el desarrollo del proyecto y cuáles no tanto?
% \end{itemize}


% %----------------------------------------------------------------------------------------
% %	SECTION 2
% %----------------------------------------------------------------------------------------
\section{Próximos pasos}

Si bien el motor de afinidad desarrollado constituye una solución robusta, escalable y ya apta para operación productiva, existen múltiples líneas de evolución que pueden ampliar su alcance, mejorar su precisión y potenciar su impacto en negocio. Estas oportunidades abarcan la incorporación de nuevas señales, el desarrollo de representaciones más ricas, el avance hacia modelos neuronales especializados, la optimización de infraestructura y la validación experimental a gran escala.

En primer lugar, un camino natural consiste en enriquecer el conjunto de señales que incorpora fuentes adicionales aún no explotadas. Entre ellas se destacan elasticidades de precio por cliente, indicadores de disponibilidad en tiempo real, atributos derivados del calendario promocional y métricas detalladas del \textit{funnel} digital, como secuencias de navegación. La literatura reciente demuestra que la combinación de señales transaccionales, contextuales y secuenciales mejora de forma sustantiva la capacidad de predicción en entornos de comercio electrónico y retail \cite{ARTICLE:Elgendy2021, ARTICLE:Gupta2019, ARTICLE:Zhang2019}. Integrar estas fuentes en el score compuesto permitiría capturar capas de comportamiento más finas y anticipar variaciones sensibles al contexto comercial.

En segundo lugar, resulta especialmente prometedor avanzar hacia métodos de segmentación dinámica y clustering avanzado que capten similitudes estructurales entre clientes y productos. El uso de técnicas como HDBSCAN \cite{ARTICLE:McInnes2017}, clustering jerárquico o modelos basados en densidad permitiría identificar subpoblaciones relevantes que no emergen de forma explícita del análisis transaccional tradicional \cite{ARTICLE:Zhang2017segmentation, ARTICLE:Sarwar2002}. Estas estructuras pueden utilizarse para construir representaciones grupales o \textit{cluster embeddings}, que combina atributos individuales con patrones colectivos, lo que facilita una generalización más sólida en escenarios de datos escasos o productos nuevos.

Un tercer eje de desarrollo se orienta a explorar arquitecturas de modelado más expresivas. Los modelos secuenciales, tales como \texttt{GRU4Rec} \cite{ARTICLE:Hidasi2016}, \texttt{SASRec} \cite{ARTICLE:Kang2018} o variantes \texttt{Transformer} especializadas en recomendación, han demostrado una capacidad superior para capturar dependencias temporales y dinámicas de corto plazo. Su incorporación permitiría ir más allá del esquema estático de seis meses utilizado en este trabajo, y ofrece recomendaciones sensibles a la evolución reciente del comportamiento del cliente. Asimismo, las técnicas multimodales basadas en embeddings visuales y textuales \cite{ARTICLE:Mikolov2013, ARTICLE:Grbovic2018} abren la puerta a mejorar la capacidad del sistema para generalizar ante productos con poco historial o recientemente introducidos al portafolio.

En términos de arquitectura, es relevante investigar modelos híbridos que combinen la escalabilidad y estabilidad de ALS con la expresividad de los modelos neuronales. La integración entre \textit{Two-Tower} y ALS, por ejemplo, puede derivar en esquemas de entrenamiento conjunto donde los embeddings aprendidos alimenten directamente la factorización matricial, lo que reduce inconsistencias entre espacios latentes y aumenta la precisión final. Adicionalmente, técnicas de \textit{knowledge distillation} \cite{ARTICLE:Tang2018, ARTICLE:Hinton2015} permitirían transferir el comportamiento de modelos complejos hacia modelos más livianos y rápidos, que disminuye el costo computacional sin sacrificar calidad.

Otra línea de mejora se vincula con la optimización de la infraestructura computacional. El uso de GPUs o \textit{clusters} heterogéneos podría acelerar significativamente los modelos neuronales; mientras que la incorporación de particionamiento inteligente, difusión selectiva de embeddings (\textit{broadcast}) y UDFs optimizadas contribuiría a reducir tiempos y costos. La adopción de componentes como \texttt{Delta Live Tables}, \texttt{Feature Store} o \textit{pipelines} \texttt{CI/CD} basados en \texttt{MLflow Model Registry} reforzaría la gobernanza y automatización del sistema, alineándose con las mejores prácticas de ingeniería de ML \cite{ARTICLE:Sculley2015, ARTICLE:Zaharia2010}.

Finalmente, un paso esencial es avanzar hacia una validación directa en negocio mediante experimentos A/B, pilotos geográficos o pruebas controladas en segmentos específicos. La literatura de experimentación controlada \cite{ARTICLE:Bakshy2014, ARTICLE:Kohavi2009, ARTICLE:Deng2013} demuestra que este enfoque es fundamental para medir impacto real en métricas operativas como crecimiento incremental de volumen, expansión del surtido, aumento del ticket promedio o reducción de compras erráticas. Complementariamente, la incorporación de explicabilidad en las recomendaciones fortalecería la adopción por parte de los equipos comerciales y mejoraría la interacción entre usuarios y el sistema.

En conjunto, estos desarrollos delinean una hoja de ruta clara para evolucionar el motor de afinidad hacia una plataforma más precisa, inteligente, multimodal y estrechamente alineada con la dinámica comercial, lo que amplía su valor estratégico dentro del ecosistema de recomendación B2B.